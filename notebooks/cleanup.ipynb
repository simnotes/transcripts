{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import german language data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "# disable truncated columns\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "\n",
    "# use full siza of display\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "# import data\n",
    "df = pd.read_csv('../corpora/de/clips.tsv', \n",
    "        sep=\"\\t\",\n",
    "        parse_dates=False,\n",
    "        engine=\"python\",\n",
    "        encoding=\"utf-8\",\n",
    "        error_bad_lines=False,\n",
    "        quotechar='\"',\n",
    "        quoting=csv.QUOTE_NONE,)\n",
    "\n",
    "# filter to german language\n",
    "df_de = df[df['locale'] == \"de\"]\n",
    "\n",
    "# only retain those datasets with at least 2 up or down-votes and more up than down-votes (aka \"valid data\")\n",
    "valid = df_de.loc[ lambda df: (df.up_votes + df.down_votes > 1) & (df.up_votes > df.down_votes), : ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply current 'common' preprocessors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "from urllib.parse import unquote\n",
    "from html.parser import HTMLParser\n",
    "\n",
    "\n",
    "class _HTMLStripper(HTMLParser):\n",
    "    \"\"\"Class that strips HTML from strings.\n",
    "\n",
    "    Examples:\n",
    "        >>> stripper = _HTMLStripper()\n",
    "        >>> stripper.feed(html)\n",
    "        >>> nohtml = stripper.get_data()\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.reset()\n",
    "        self.strict = False\n",
    "        self.convert_charrefs = True\n",
    "        self.fed = []\n",
    "\n",
    "    def handle_data(self, d):\n",
    "        self.fed.append(d)\n",
    "\n",
    "    def get_data(self):\n",
    "        return \"\".join(self.fed)\n",
    "\n",
    "\n",
    "def _strip_tags(html):\n",
    "    \"\"\"Removes HTML tags from passed text.\n",
    "\n",
    "    Args:\n",
    "      html (str): String containing HTML\n",
    "\n",
    "    Returns:\n",
    "      (str): String with HTML removed\n",
    "    \"\"\"\n",
    "    s = _HTMLStripper()\n",
    "    s.feed(html)\n",
    "    return s.get_data()\n",
    "\n",
    "\n",
    "def _strip_string(sentence):\n",
    "    \"\"\"Cleans a string based on a whitelist of printable unicode categories.\n",
    "\n",
    "    You can find a full list of categories here:\n",
    "    http://www.fileformat.info/info/unicode/category/index.htm\n",
    "    \"\"\"\n",
    "    letters     = ('LC', 'Ll', 'Lm', 'Lo', 'Lt', 'Lu')\n",
    "    numbers     = ('Nd', 'Nl', 'No')\n",
    "    marks       = ('Mc', 'Me', 'Mn')\n",
    "    punctuation = ('Pc', 'Pd', 'Pe', 'Pf', 'Pi', 'Po', 'Ps')\n",
    "    symbol      = ('Sc', 'Sk', 'Sm', 'So')\n",
    "    space       = ('Zs',)\n",
    "\n",
    "    allowed_categories = letters + numbers + marks + punctuation + symbol + space\n",
    "\n",
    "    return u''.join([c for c in sentence if unicodedata.category(c) in allowed_categories])\n",
    "\n",
    "\n",
    "def common(sentence):\n",
    "    \"\"\"Cleans up the passed sentence in a language independent manner, removing or reformatting invalid data.\n",
    "\n",
    "    Args:\n",
    "      sentence (str): Sentence to be cleaned up.\n",
    "\n",
    "    Returns:\n",
    "      (str): Cleaned up sentence. Returning None or a `str` of whitespace flags the sentence as invalid.\n",
    "    \"\"\"\n",
    "\n",
    "    # Decode any URL encoded elements of sentence\n",
    "    sentence = unquote(sentence)\n",
    "    # Remove any HTML tags\n",
    "    sentence = _strip_tags(sentence)\n",
    "    # Remove non-printable characters\n",
    "    sentence = _strip_string(sentence)\n",
    "    # TODO: Clean up data in a language independent manner\n",
    "    return sentence\n",
    "\n",
    "\n",
    "valid.loc[:, ('sentence')] = valid[\"sentence\"].apply(func=lambda t: common(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply current 'de' preprocessors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _preprocessor_wrapper(client_id, sentence, up_votes, down_votes):\n",
    "    sentence = de(client_id, sentence)\n",
    "    if None == sentence or not sentence.strip():\n",
    "        up_votes = 0\n",
    "        down_votes = 2\n",
    "    return pd.Series([sentence, up_votes, down_votes])\n",
    "\n",
    "import re\n",
    "QUOTE_PATTERN = re.compile(r'^\\\"{3}(.*)\\\"{2}(.*)\\\"{1}$')\n",
    "QUOTE_PATTERN_2 = re.compile(r'^\\\"{1}(.*)\\\"{2}(.*)\\\"{2}(.*)\\\"{1}$')\n",
    "QUOTE_PATTERN_3 = re.compile(r'^\\\"{1}(.*)\\\"{1}')\n",
    "    \n",
    "def _remove_multi_quotes(sentence):\n",
    "    \"\"\"Removes all quotes from patterns like \n",
    "    \\\"\\\"\\\"content\\\"\\\"content\\\" or\n",
    "    \\\"content\\\"\\\"content\\\"\\\"content\\\" or\n",
    "    \\\"content\\\"\n",
    "    \n",
    "    Args:\n",
    "      sentence (str): Sentence to be cleaned up.\n",
    "      \n",
    "    Returns:\n",
    "      (str): Cleaned up sentence. Returns the sentence 'as-is', if matching\n",
    "      did not work as expected\n",
    "    \"\"\"\n",
    "    matches = QUOTE_PATTERN.match(sentence) # pattern: \\\"\\\"\\\"content\\\"\\\"content\\\"\n",
    "    matches2 = QUOTE_PATTERN_2.match(sentence) # pattern: \\\"content\\\"\\\"content\\\"\\\"content\\\"\n",
    "    matches3 = QUOTE_PATTERN_3.match(sentence) # patter: \\\"content\\\"\n",
    "    \n",
    "    if matches != None and matches.lastindex == 2:\n",
    "        return \"{}{}\".format(matches.group(1), matches.group(2))\n",
    "    elif matches2 != None and matches2.lastindex == 3:\n",
    "        return \"{}{}{}\".format(matches2.group(1), matches2.group(2), matches2.group(3))\n",
    "    elif matches3 != None and matches3.lastindex == 1:\n",
    "        return \"{}\".format(matches3.group(1))\n",
    "    \n",
    "    return sentence\n",
    "   \n",
    "                             \n",
    "def de(client_id, sentence):\n",
    "    \"\"\"Cleans up the passed sentence, removing or reformatting invalid data.\n",
    "\n",
    "    Args:\n",
    "      client_id (str): Client ID of sentence's speaker\n",
    "      sentence (str): Sentence to be cleaned up.\n",
    "\n",
    "    Returns:\n",
    "      (str): Cleaned up sentence. Returning None or a `str` of whitespace flags the sentence as invalid.\n",
    "    \"\"\"\n",
    "    # Remove quotation mark patterns\n",
    "    sentence = _remove_multi_quotes(sentence)\n",
    "    \n",
    "    # TODO: Clean up de data\n",
    "    return sentence\n",
    "\n",
    "test = valid.copy(deep=True)\n",
    "\n",
    "test[[\"sentence\", \"up_votes\", \"down_votes\"]] = test[[\"client_id\", \"sentence\", \"up_votes\", \"down_votes\"]].apply(func=lambda arg: _preprocessor_wrapper(*arg), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "test['sentence'].drop_duplicates().sort_values(ascending=True).iloc[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
