{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XOR Train Dev Test\n",
    "\n",
    "This notebook will show and document a method of how to split former validated Mozilla Common Voice data into train, dev and test datasets so that values of the column \"client_id\" of one dataset is not intersecting with one of the other datasets. \n",
    "\n",
    "In this analysis only german language data will be processed\n",
    "\n",
    "## Import and prepare data\n",
    "\n",
    "Data will be imported and prepared according to \\_partition_corpus_data() and \\_post_process_valid_data()\n",
    "\n",
    "Reference: https://github.com/mozilla/CorporaCreator/blob/master/src/corporacreator/corpus.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "# disable truncated columns\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "\n",
    "# use full siza of display / can be enabled on bigger screens\n",
    "#from IPython.core.display import display, HTML\n",
    "#display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "# import data\n",
    "df = pd.read_csv('../corpora/de/clips.tsv', \n",
    "        sep=\"\\t\",\n",
    "        parse_dates=False,\n",
    "        engine=\"python\",\n",
    "        encoding=\"utf-8\",\n",
    "        error_bad_lines=False,\n",
    "        quotechar='\"',\n",
    "        quoting=csv.QUOTE_NONE,)\n",
    "\n",
    "# filter to german language\n",
    "df_de = df[df['locale'] == \"de\"]\n",
    "\n",
    "# only retain those datasets with at least 2 up or down-votes and more up than down-votes (aka \"valid data\")\n",
    "valid = df_de.loc[ lambda df: (df.up_votes + df.down_votes > 1) & (df.up_votes > df.down_votes), : ]\n",
    "\n",
    "# more power users in train, others in dev or test\n",
    "speaker_counts = valid[\"client_id\"].value_counts()\n",
    "speaker_counts = speaker_counts.to_frame().reset_index()\n",
    "speaker_counts.columns = [\"client_id\", \"user_sentence_count\"]\n",
    "\n",
    "valid = valid.join(speaker_counts.set_index(\"client_id\"), on=\"client_id\")\n",
    "valid = valid.sort_values([\"user_sentence_count\", \"client_id\"])\n",
    "valid_tmp = valid.groupby(\"sentence\").head(1) # 1 => multiple sentence count command line argument \n",
    "valid_tmp.sort_values([\"user_sentence_count\", \"client_id\"], ascending=False)\n",
    "valid_tmp = valid_tmp.drop(columns=\"user_sentence_count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate optimal split-sizes according to current applied \"sample theory\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2726, 2342, 2342)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sample_size(population_size):\n",
    "    \"\"\"Calculates the sample size.\n",
    "    Calculates the sample size required to draw from a population size `population_size`\n",
    "    with a confidence level of 99% and a margin of error of 1%.\n",
    "    Args:\n",
    "      population_size (int): The population size to draw from.\n",
    "    \"\"\"\n",
    "    margin_of_error = 0.01\n",
    "    fraction_picking = 0.50\n",
    "    z_score = 2.58 # Corresponds to confidence level 99%\n",
    "    numerator = (z_score**2 * fraction_picking * (1 - fraction_picking)) / (margin_of_error**2)\n",
    "    denominator = 1 + (z_score**2 * fraction_picking * (1 - fraction_picking)) / (margin_of_error**2 * population_size)\n",
    "    return numerator / denominator\n",
    "\n",
    "def calculate_data_set_sizes(total_size):\n",
    "    # Find maximum size for the training data set in accord with sample theory\n",
    "    for train_size in range(total_size, 0, -1):\n",
    "        calculated_sample_size = int(sample_size(train_size))\n",
    "        if 2 * calculated_sample_size + train_size <= total_size:\n",
    "            dev_size = calculated_sample_size\n",
    "            test_size = calculated_sample_size\n",
    "            break\n",
    "    return train_size, dev_size, test_size\n",
    "\n",
    "\n",
    "train_size, dev_size, test_size = calculate_data_set_sizes(len(valid_tmp))\n",
    "train_size, dev_size, test_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset via old/current method with regard to calculated sizes only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_old = valid_tmp.iloc[0:train_size]\n",
    "dev_old = valid_tmp.iloc[train_size : train_size + dev_size]\n",
    "test_old = valid_tmp.iloc[train_size + dev_size : train_size + dev_size + test_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset via new method according to calculated sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2728, 2342, 2342)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate continous index per client_id, so we can loop over it\n",
    "continous_client_index, uniques = pd.factorize(valid_tmp[\"client_id\"])\n",
    "valid_tmp[\"continous_client_index\"] = continous_client_index\n",
    "\n",
    "# create empty dataframes with fitting column layout\n",
    "train_new = pd.DataFrame(columns=valid_tmp.columns)\n",
    "dev_new = pd.DataFrame(columns=valid_tmp.columns)\n",
    "test_new = pd.DataFrame(columns=valid_tmp.columns)\n",
    "\n",
    "# iterate over continous index in reverse order so\n",
    "# test dataset will be populated with clients with less entries in base dataset first\n",
    "# dev dataset will be populated second\n",
    "# train dataset will be populated with clients having the most entries in dataset (i.e. \"power users\")\n",
    "for i in range(max(continous_client_index), -1, -1):\n",
    "    if len(test_new) + len(valid_tmp[valid_tmp[\"continous_client_index\"] == i]) <= test_size:\n",
    "        test_new = pd.concat([test_new, valid_tmp[valid_tmp[\"continous_client_index\"] == i]])\n",
    "    elif len(dev_new) + len(valid_tmp[valid_tmp[\"continous_client_index\"] == i]) <= dev_size:\n",
    "        dev_new = pd.concat([dev_new, valid_tmp[valid_tmp[\"continous_client_index\"] == i]])\n",
    "    else:\n",
    "        train_new = pd.concat([train_new, valid_tmp[valid_tmp[\"continous_client_index\"] == i]])\n",
    "    \n",
    "train_new_size = len(train_new)\n",
    "dev_new_size = len(dev_new)\n",
    "test_new_new = len(test_new)\n",
    "\n",
    "train_new_size, dev_new_size, test_new_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate dataset intersections to compare old method with new method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_client_intersections(train, dev, test):\n",
    "    def indexing(df):\n",
    "        df = df[\"client_id\"].drop_duplicates().to_frame().reset_index()\n",
    "        df = df.set_index(\"client_id\")\n",
    "        return df.index\n",
    "\n",
    "    train_index = indexing(train)\n",
    "    test_index = indexing(test)\n",
    "    dev_index = indexing(dev)\n",
    "\n",
    "    inter_train_test = train_index.intersection(test_index)\n",
    "    inter_train_dev = train_index.intersection(dev_index)\n",
    "    inter_test_dev = test_index.intersection(dev_index)\n",
    "\n",
    "    print(\"{} intersecting client_id in train/test\".format(len(inter_train_test)))\n",
    "    print(\"{} intersecting client_id in train/dev\".format(len(inter_train_dev)))\n",
    "    print(\"{} intersecting client_id in test/dev\".format(len(inter_test_dev)))\n",
    "    \n",
    "    return inter_train_test, inter_train_dev, inter_test_dev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 intersecting client_id in train/test\n",
      "0 intersecting client_id in train/dev\n",
      "1 intersecting client_id in test/dev\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Index([], dtype='object', name='client_id'),\n",
       " Index([], dtype='object', name='client_id'),\n",
       " Index(['91a51969a700b958699a7242d420d6d4e62f63034f8872eafcbb1953552568c819e9670c4350bc121446d4d4d356c23f8f710a1850d5292f33907e6ce858f4eb'], dtype='object', name='client_id'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_client_intersections(train_old, dev_old, test_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 intersecting client_id in train/test\n",
      "0 intersecting client_id in train/dev\n",
      "0 intersecting client_id in test/dev\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Index([], dtype='object', name='client_id'),\n",
       " Index([], dtype='object', name='client_id'),\n",
       " Index([], dtype='object', name='client_id'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_client_intersections(train_new, dev_new, test_new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
